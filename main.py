import os
import difflib
import unicodedata
import re
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from openai import OpenAI
from pinecone import Pinecone

# --- KONFIGUR√ÅCI√ì ---
load_dotenv()
INDEX_NAME = "booksy-index"

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], 
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str

class HookRequest(BaseModel):
    url: str
    page_title: str
    visitor_type: str 
    cart_status: str 
    lang: str

# --- SEG√âDF√úGGV√âNYEK ---
def normalize_text(text):
    """√âkezetmentes√≠t√©s, kisbet≈±s√≠t√©s, tiszt√≠t√°s"""
    if not text: return ""
    text = str(text).lower()
    return ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')

class BooksyBrain:
    def __init__(self):
        self.api_key_openai = os.getenv("OPENAI_API_KEY")
        self.api_key_pinecone = os.getenv("PINECONE_API_KEY")
        self.client_ai = OpenAI(api_key=self.api_key_openai)
        self.pc = Pinecone(api_key=self.api_key_pinecone)
        self.index = self.pc.Index(INDEX_NAME)

        self.store_policy = """
        [SZ√ÅLL√çT√ÅS: Feldolgoz√°s (2-4 nap rakt√°r / 7-30 nap k√ºls≈ë) + Fut√°r (24-48h RO, 2-4 nap HU).]
        """

    def generate_sales_hook(self, ctx: HookRequest):
        try:
            response = self.client_ai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"Context: Lang {ctx.lang}, Page {ctx.page_title}, Cart {ctx.cart_status}. Generate short sales hook (max 6 words)."},
                    {"role": "user", "content": "Hook me."}
                ],
                temperature=0.7, max_tokens=30
            )
            return response.choices[0].message.content.strip()
        except:
            return "BunƒÉ! Te pot ajuta?" if ctx.lang == 'ro' else "Szia! Seg√≠thetek?"

    def generate_search_params(self, user_input):
        try:
            # Itt most KEV√âSB√â hagyjuk az AI-t fant√°zi√°lni a kulcsszavakr√≥l,
            # hogy a szigor√∫ sz≈±r√©s pontos maradjon.
            response = self.client_ai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": """
                     Analyze user query.
                     1. Language (hu/ro).
                     2. Intent (SEARCH/INFO).
                     3. Scope (ALL/SPECIFIC).
                     4. KEYWORDS: Extract the main entities (Author, Title, Topic). Remove filler words.
                     Output: LANG | SCOPE | INTENT | KEYWORDS
                     """},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.1
            )
            parts = response.choices[0].message.content.split('|')
            return parts[0].strip().lower(), parts[1].strip(), parts[2].strip(), parts[3].strip()
        except:
            return "hu", "SPECIFIC", "SEARCH", user_input

    def search_books(self, query_text, lang_filter, scope):
        try:
            # 1. K√âSZLET SZ≈∞R√âS (K√ñTELEZ≈ê!)
            filter_criteria = {"stock": "instock"}
            if scope != 'ALL' and lang_filter in ['hu', 'ro']:
                filter_criteria["lang"] = lang_filter
            
            # 2. Vektoros Keres√©s (Nagy mer√≠t√©s)
            response = self.client_ai.embeddings.create(input=query_text, model="text-embedding-3-small")
            raw_results = self.index.query(
                vector=response.data[0].embedding,
                top_k=100, # 100-at k√©r√ºnk, hogy biztos benne legyen a j√≥
                include_metadata=True, 
                filter=filter_criteria
            )

            matches = raw_results.get('matches', [])
            if not matches: return {"matches": []}

            # --- 3. V16 KULCSSZ√ì K√âNYSZER√çT√âS (Enforcement) ---
            
            # Kulcsszavak tiszt√≠t√°sa
            stop_words = [
                'a', 'az', 'egy', 'es', 'vagy', 'hogy', 'van', 
                'konyv', 'konyvek', 'konyvet', 'konyvei', # Fontos: a 'k√∂nyvei' is kuka
                'carte', 'carti', 'cartile', 
                'keresek', 'keres', 'szeretnek', 'vennek', 
                'kiado', 'szerzo', 'cim', 'regeny'
            ]
            
            normalized_query = normalize_text(query_text)
            # Csak a l√©nyegi szavakat tartjuk meg (min 3 karakter)
            keywords = [w for w in normalized_query.split() if w not in stop_words and len(w) > 2]

            filtered_results = []

            for match in matches:
                meta = match['metadata']
                # Egyes√≠tj√ºk a kereshet≈ë mez≈ëket egy nagy stringg√©
                searchable_content = normalize_text(str(meta.get('title', ''))) + " " + \
                                     normalize_text(str(meta.get('author', ''))) + " " + \
                                     normalize_text(str(meta.get('category', '')))
                
                # SZAB√ÅLY:
                # Ha a felhaszn√°l√≥ √≠rt kulcsszavakat (pl. "Berente", "Agi"),
                # akkor LEGAL√ÅBB AZ EGYIKNEK benne kell lennie a k√∂nyvben.
                # De ha t√∂bbszavas a n√©v, akkor ink√°bb az √ñSSZESNEK (Szigor√∫ AND).
                
                if not keywords:
                    # Ha nincs kulcssz√≥ (pl. csak "k√∂nyvek"), akkor a vektor d√∂nt
                    filtered_results.append(match)
                    continue

                # K√âNYSZER√çT√âS: Minden kulcssz√≥ benne van?
                # Ezzel dobjuk ki a "Berkesi"-t (mert nincs benne az "Agi" √©s a "Berente")
                all_keywords_present = True
                for kw in keywords:
                    if kw not in searchable_content:
                        all_keywords_present = False
                        break
                
                if all_keywords_present:
                    filtered_results.append(match)

            # Ha a szigor√∫ sz≈±r√©s ut√°n maradt valami, azt adjuk vissza
            if filtered_results:
                print(f"Enforced Filter: Found {len(filtered_results)} exact matches.")
                # Rendez√©s √°r vagy score szerint? Maradjunk a score-n√°l (relevancia)
                filtered_results.sort(key=lambda x: x['score'], reverse=True)
                return {"matches": filtered_results[:25]}
            
            # Ha a szigor√∫ sz≈±r√©s t√∫l sok mindent kievett (√ºres lett), 
            # akkor visszat√©r√ºnk a vektoros eredm√©nyhez, de csak a nagyon er≈ësekhez.
            # Ez a "Safety Net".
            print("Enforced filter found nothing, falling back to strong vector matches.")
            strong_matches = [m for m in matches if m['score'] > 0.60]
            return {"matches": strong_matches[:25]}

        except Exception as e:
            print(f"Keres√©si hiba: {e}")
            return {"matches": []}

    def process_message(self, user_input):
        detected_lang, scope, intent, keywords = self.generate_search_params(user_input)
        context_text = ""
        found_products = [] 
        
        footer_hu = "\n\nüí° *Tipp: Jelenleg a nyelvednek megfelel≈ë k√∂nyveket keresem. Ha mindent l√°tni szeretn√©l, √≠rd hozz√°: ‚Äûminden nyelven‚Äù!*"
        footer_ro = "\n\nüí° *Sfat: Caut cƒÉr»õi √Æn limba ta. DacƒÉ vrei sƒÉ vezi toate limbile, adaugƒÉ: ‚Äûtoate limbile‚Äù!*"

        if intent == "SEARCH":
            results = self.search_books(keywords, detected_lang, scope)
            seen_titles = []
            
            if not results.get('matches'):
                msg = "Nu am gƒÉsit rezultate √Æn stoc." if detected_lang == 'ro' else "Sajnos nem tal√°ltam k√©szleten l√©v≈ë k√∂nyvet ezzel a keres√©ssel."
                return {"reply": msg + (footer_ro if detected_lang == 'ro' else footer_hu), "products": []}

            for match in results['matches']:
                # Itt m√°r nem kell score filter, mert a search_books m√°r sz≈±rt
                meta = match['metadata']
                title = str(meta.get('title', 'N/A'))
                
                is_dup = False
                for seen in seen_titles:
                    if difflib.SequenceMatcher(None, title.lower(), seen.lower()).ratio() > 0.85:
                        is_dup = True; break
                if is_dup: continue
                seen_titles.append(title)
                
                product_data = {
                    "title": title,
                    "price": meta.get('price', 'N/A'), 
                    "url": meta.get('url', '#'),
                    "image": meta.get('image_url', '') 
                }
                found_products.append(product_data)
                
                author = meta.get('author', 'N/A')
                cat_tag = meta.get('category', 'N/A')
                
                context_text += f"- {title} (Szerz≈ë: {author}, √År: {meta.get('price')} RON, Kateg√≥ria: {cat_tag})\n"
                
                if len(found_products) >= 8: break 
            
            if not found_products:
                msg = "Nu am gƒÉsit nimic relevant." if detected_lang == 'ro' else "Sajnos nem tal√°ltam relev√°ns k√∂nyvet."
                return {"reply": msg + (footer_ro if detected_lang == 'ro' else footer_hu), "products": []}

        else:
            context_text = "HASZN√ÅLD A TUD√ÅSB√ÅZIST!"

        lang_instruction = "Reply in ROMANIAN only." if detected_lang == 'ro' else "Reply in HUNGARIAN only."
        system_prompt = f"Te Booksy vagy. {self.store_policy} Csak a list√°zott k√∂nyvekr≈ël besz√©lj."

        response = self.client_ai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "system", "content": lang_instruction},
                {"role": "user", "content": f"User: {user_input}\nFound Books:\n{context_text}"}
            ],
            temperature=0.3
        )
        
        final_reply = response.choices[0].message.content
        if scope != 'ALL': final_reply += footer_ro if detected_lang == 'ro' else footer_hu
        return {"reply": final_reply, "products": found_products}

bot = BooksyBrain()

@app.get("/")
def home(): return {"status": "Booksy V16 (Instock + Strict Keyword Enforcement)"}

@app.post("/hook")
def hook_endpoint(request: HookRequest):
    return {"hook": bot.generate_sales_hook(request)}

@app.post("/chat")
def chat_endpoint(request: ChatRequest):
    return bot.process_message(request.message)